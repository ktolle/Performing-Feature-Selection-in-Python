{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Feature Selection\n",
    "Question: Why do we do feature selection? \n",
    "Answer: In order to have the most predictive model we can for the least computational cost. \n",
    "\n",
    "How we do this is by eliminating independent variables that are nonpredictive or only marginally so. This reduces the chance of overfitting to the features, increases accuracy and shortens time to convergence. \n",
    "\n",
    "This notebook is a walk through several of the examples in the scikit learn site(https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection), back-to-back. I not only show you how to find out the most predictive features, I show you how to display them to the screen and put these top features into a new dataframe so that you can use that dataframe as input to a downstream process (something often frustratingly not shown my others). \n",
    "\n",
    "Caveat: I should have written the conversion to a new dataframe as a #def, but I got too focused on finishing it. On the one hand, that means you can just use each section as a \"complete\" notebook. I often do this because it is easier in the classroom to show them inline. There is also some slight variations due to different attributes that are available for each feature selection method. The only downside is that this notebook is much longer than most of the ones I publish.\n",
    "\n",
    "The Feature Selection Techniques covered are: \n",
    "* SelectKBest\n",
    "* Recursive Feature Elimination (RFE)\n",
    "* RFE with Cross Validation (a favorite of mine as my students know)\n",
    "* SelectFromModel\n",
    "* Extra Tree Classification\n",
    "\n",
    "NOTE: these are being used for classification and the dataset is the extended Wisconsin Breast Cancer dataset: https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read in the file from UCI <recommend you save locally and load it if your connectivity is iffy>\n",
    "\n",
    "# Loading the file over the internet\n",
    "#filename = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\" \n",
    "\n",
    "# Loading the file locally in the same folder as the Python Notebook\n",
    "filename = \"wi_breast_cancer.csv\"\n",
    "names = ['ID','Diagnosis',\n",
    "         'Mean-Radius','Mean-Texture','Mean-Perimeter',\n",
    "         'Mean-Area','Mean-Smoothness','Mean-Compactness',\n",
    "         'Mean-Concavity','Mean-ConcavePoints',\n",
    "         'Mean-Symmetry','Mean-FractalDimension', \n",
    "         'StdErr-Radius','StdErr-Texture','StdErr-Perimeter',\n",
    "         'StdErr-Area','StdErr-Smoothness','StdErr-Compactness',\n",
    "         'StdErr-Concavity','StdErr-ConcavePoints',\n",
    "         'StdErr-Symmetry','StdErr-FractalDimension',\n",
    "         'Worst-Radius','Worst-Texture','Worst-Perimeter',\n",
    "         'Worst-Area','Worst-Smoothness','Worst-Compactness',\n",
    "         'Worst-Concavity','Worst-ConcavePoints',\n",
    "         'Worst-Symmetry','Worst-FractalDimension']\n",
    "\n",
    "# loading the file into a dataframe\n",
    "data = pd.read_csv(filename, names=names, header=None) \n",
    "\n",
    "# Convert the Diagnosis to a numeric variable\n",
    "data['Diagnosis'] = data['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "# Malignant tumors = 1 or True and Benign tumors = 0 or False\n",
    "\n",
    "# Loading the X and y matrices\n",
    "X = data.iloc[:, 2:32]   # load features into X dataframe\n",
    "Y = data.iloc[:, 1]      # Load target into y dataframe\n",
    "\n",
    "# Get the rows and columns of the numpy array\n",
    "(nRows, nCols) = X.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectKBest Features \n",
    "Testing SelectKBest in order to ensure we are using the right features for our dataset. The example below uses the Chi-Squared ${(Ï‡2)}$ statistical test for non-negative features to select the best features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Setting precision for display\n",
    "#pd.options.display.precision = 2\n",
    "#np.set_printoptions(precision = 2)\n",
    "\n",
    "fitScores = []\n",
    "\n",
    "# feature extraction; where k is the number of features you want to select\n",
    "test = SelectKBest(score_func=chi2, k=5)\n",
    "fit = test.fit(X, Y)\n",
    "\n",
    "# Find the scores for every feature so that you know which were selected\n",
    "fitScores = fit.scores_\n",
    "\n",
    "# Convert the numpy array of scores back into a DF with the correct column names\n",
    "features = pd.DataFrame(fitScores.reshape(-1, len(fitScores)),columns=names[2:32])\n",
    "print(features.T) # transpose to make it easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eyeballing the top scores and creating a header for them\n",
    "# We will see a better way in upcoming sections that use code to do this\n",
    "heads = ['Mean-Perimeter','Mean-Area','StdErr-Area','Worst-Perimeter','Worst-Area']\n",
    "\n",
    "# perform the selection of fields so we have them for later analysis\n",
    "kSelect = SelectKBest(chi2, k=5).fit_transform(X, Y)\n",
    "(rows, cols) = kSelect.shape \n",
    "\n",
    "# Create a dataframe to hold the selected values (only) for later processing\n",
    "selected = pd.DataFrame(data=kSelect,\n",
    "          index=np.array(range(1, rows+1)),\n",
    "          columns=np.array(range(1, cols+1)))\n",
    "\n",
    "# Add the column headers for the X array--the range from names for this dataframe\n",
    "selected.columns = heads \n",
    "selected.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "Recursively removes attributes and builds models on those attributes that remain. It accomplishes this by training on the full set then determining the feature importances given the model selected then it prunes the worst, the next worst and so on building a model each time until it ends up with the final set. Default removal each time (step) is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# feature extraction \n",
    "model = LogisticRegression() \n",
    "rfe = RFE(model, 5) # where the number is the features retained\n",
    "rfe = rfe.fit(X,Y) \n",
    "\n",
    "ranking = rfe.ranking_\n",
    "selected = rfe.support_\n",
    "\n",
    "ranking = np.vstack((ranking, selected))\n",
    "\n",
    "(rows, cols) = ranking.shape\n",
    "\n",
    "# This dataframe doesn't hold the columns selected, \n",
    "# it is only for pretty printing the selected features\n",
    "rfe_selected = pd.DataFrame(data=ranking,\n",
    "          index=np.array(range(1, rows+1)),\n",
    "          columns=np.array(range(1, cols+1)))\n",
    "rfe_selected.columns = names[2:32] \n",
    "\n",
    "array = rfe_selected.T # transpose\n",
    "array.columns = ['rank', 'selected']\n",
    "output = array['selected'] == 1\n",
    "df = array[selected]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual features selected for later processing\n",
    "rfeSelect = RFE(model,5).fit_transform(X, Y)\n",
    "\n",
    "# Get the size of the array of selected values \n",
    "(rows, cols) = rfeSelect.shape\n",
    "\n",
    "# Get the column headings and remove the selection data\n",
    "df2 = df.T # transpose back... :-)\n",
    "heads = df2.iloc[0:0]\n",
    "heads = heads.columns\n",
    "\n",
    "# Create a dataframe to hold the selected values (only) for later processing\n",
    "selectedRFE = pd.DataFrame(data=rfeSelect,\n",
    "          index=np.array(range(1, rows+1)),\n",
    "          columns=np.array(range(1, cols+1)))\n",
    "\n",
    "# Add the column headers for the X array--the range from names for this dataframe\n",
    "selectedRFE.columns = heads \n",
    "selectedRFE.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important thing to note is that the top ones do not correspond with kSelect choices Given this is robust, and that it was tested by removing variables to see which models perform best, this method is quite likely to give better results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive removal with cross validation\n",
    "In this case we will be using a support vector machine and RFECV to identify the top features. This is still a recursive removal, but it is more  comprehensive than a simple RFE. It also allows for automatic tuning of the number of features selected, rather than the data scientist having to set the number in advance or test the the best number of values number through trial and error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "svc = SVC(kernel=\"linear\") # using linear, but also use poly or radial basis \n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X, Y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "#print(\"Selected Features: %s\" % rfecv.support_) \n",
    "#print(\"Feature Ranking: %s\" % rfecv.ranking_)\n",
    "\n",
    "rankingCV = rfecv.ranking_\n",
    "selectedCV = rfecv.support_\n",
    "\n",
    "rankingCV = np.vstack((rankingCV, selectedCV))\n",
    "(rows, cols) = rankingCV.shape\n",
    "\n",
    "# This dataframe for pretty printing the selected features\n",
    "rfecv_selected = pd.DataFrame(data=rankingCV,\n",
    "          index=np.array(range(1, rows+1)),\n",
    "          columns=np.array(range(1, cols+1)))\n",
    "rfecv_selected.columns = names[2:32] \n",
    "\n",
    "arrayCV = rfecv_selected.T\n",
    "arrayCV.columns = ['rankCV', 'selectedCV']\n",
    "output = arrayCV['selectedCV'] == 1\n",
    "dfCV = arrayCV[selectedCV]\n",
    "print(dfCV)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "# it's handy that RFECV has the grid_scores features\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual features selected for later processing\n",
    "rfecvFeatures = rfecv.transform(X)\n",
    "\n",
    "# Get the size of the array of selected values \n",
    "(rows, cols) = rfecvFeatures.shape\n",
    "#print(rows, cols)\n",
    "\n",
    "# Get the column headings and remove the selection data\n",
    "df3 = dfCV.T\n",
    "heads = df3.iloc[0:0]\n",
    "heads = heads.columns\n",
    "\n",
    "# Create a dataframe to hold the selected values (only) for later processing\n",
    "selectedRFECV = pd.DataFrame(data=rfecvFeatures,\n",
    "          index=np.array(range(1, rows+1)),\n",
    "          columns=np.array(range(1, cols+1)))\n",
    "\n",
    "# Add the column headers for the X array--the range from names for this dataframe\n",
    "selectedRFECV.columns = heads \n",
    "selectedRFECV.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good news is that RFECV selected the same five features as RFE and showed us that we were cutting too deeply. That there is significant variance explained by five features (see the local maxima at 4-5), but that the next 3 features, when included with the first five, result in even better predictability. We plateau again after that, but don't see a drop in predictability until we reach 19 variables, where the prediction actually gets worse by including these and the remainder variables. Most of these come from those that were generated using standard error. To be the most efficient, quite likely you'd rerun RFE and select the top 8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select From Model\n",
    "This is what is referred to as a \"meta-transformer\" it can be used alongside any type of estimator with the coeffient (coef) or feature importance attribute post fitting the data to the model. Instead of selecting the number of features, it selects features that are below a threshold that you provide. The trick is knowing what that threshold should be, but there are ways, as we saw in RFECV to get at this information. In this instance, I'll be using the LASSO cross validation technique (Lasso.CV) which uses KFold as the cross validator by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "clf = LassoCV(cv=5)\n",
    "sfm = SelectFromModel(clf)\n",
    "sfmFeatures = sfm.fit_transform(X,Y)\n",
    "\n",
    "(rows, cols) = sfmFeatures.shape\n",
    "#print(rows, cols)\n",
    "\n",
    "# This dataframe for pretty printing the selected features\n",
    "sfm_selected = pd.DataFrame(data=sfmFeatures,\n",
    "          index=np.array(range(1, rows+1)),\n",
    "          columns=np.array(range(1, cols+1)))\n",
    "sfm_selected.columns = ['Mean-Area','Worst-Texture','Worst-Perimeter',\"Worst-Smoothness\"] \n",
    "\n",
    "sfm_selected.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I had to \"eyeball\" this one (go back to the datafile) to find the features that were selected due to the lack of \"helper\" functions I used in the previous sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance via ExtraTreesClassifier\n",
    "Bagged trees like Random Forest and Extra Trees can be used to estimate the importance of features. Extra Trees implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "np.random.seed(101) # make this stochastic decision tree deterministic\n",
    "\n",
    "etc = ExtraTreesClassifier().fit(X, Y) \n",
    "etcFeatures = etc.feature_importances_\n",
    "\n",
    "dfFeatures = pd.DataFrame(etcFeatures.reshape(-1, len(etcFeatures)),columns=names[2:32])\n",
    "dfFeatures.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees, as they are implemented, are stochastic. The issue is that each time you run it you will get a different set of features--which sucks if you are looking for a consistent set to choose from and expect the same results every time. The trick I learned on StackOverflow is to add this line to make it deterministic. \n",
    "<code> np.random.seed(101) </code>\n",
    "* Worst-Area\n",
    "* StdErr-Radius\n",
    "* Mean-ConcavePoints\n",
    "* Worst-Perimeter\n",
    "* Mean-Radius\n",
    "* Mean-Area\n",
    "* Mean-Perimeter\n",
    "* Worst-ConcavePoints\n",
    "* Worst-Radius\n",
    "* StdErr-Area\n",
    "\n",
    "The other problem, as with some examples above is the lack of helper classes, but at least with trees you can visualize them. See my Decision Tree lesson for how you can do that. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
